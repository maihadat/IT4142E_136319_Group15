{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tranvuongquocdat/Semester20221_IntroToDataScience_CapstoneProject.git"
      ],
      "metadata": {
        "id": "AdZYLDon856W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "cTBFHHyNMg7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4hIRM8C8gEL"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI2DqGx-8gES"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "cDokdmit8gEW"
      },
      "source": [
        "## Load the training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE4G7pio8gEX"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/Semester20221_IntroToDataScience_CapstoneProject/data/training_set.csv\")\n",
        "df_test = pd.read_csv(\"/content/Semester20221_IntroToDataScience_CapstoneProject/data/testing_set.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n",
        "df_test.drop([\"Unnamed: 0\"], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "4HmpZdqNInJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Ho-1gh8gEY"
      },
      "outputs": [],
      "source": [
        "#Train test split\n",
        "X_train = df_train.iloc[:, :-1]\n",
        "y_train = df_train[\"price\"]\n",
        "X_test = df_test.iloc[:, :-1]\n",
        "y_test = df_test[\"price\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10bIdDRh8gEZ"
      },
      "source": [
        "## SGDRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5_mOU3_8gEa"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "reg = SGDRegressor(max_iter=1000, tol=1e-3, learning_rate='constant', eta0=0.1)\n",
        "\n",
        "# Fit the model to the data\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Print the coefficients\n",
        "print(\"Intercept: \", reg.intercept_)\n",
        "print(\"Coefficients: \", reg.coef_)\n",
        "\n",
        "# Generate predictions for the data\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Calculate the evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Mean Absolute Error: \", mae)\n",
        "print(\"Mean Squared Error: \", mse)\n",
        "print(\"R-Squared: \", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvcy5qAQ8gEd"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f414ES5F8gEe"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"n_estimators\": 500,\n",
        "    \"max_depth\": 4,\n",
        "    \"min_samples_split\": 5,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"loss\": \"squared_error\",\n",
        "}\n",
        "\n",
        "reg = GradientBoostingRegressor(**params)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
        "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfScFMC38gEg"
      },
      "outputs": [],
      "source": [
        "test_score = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\n",
        "for i, y_pred in enumerate(reg.staged_predict(X_test)):\n",
        "    test_score[i] = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.subplot(1, 1, 1)\n",
        "plt.title(\"Deviance\")\n",
        "plt.plot(\n",
        "    np.arange(params[\"n_estimators\"]) + 1,\n",
        "    reg.train_score_,\n",
        "    \"b-\",\n",
        "    label=\"Training Set Deviance\",\n",
        ")\n",
        "plt.plot(\n",
        "    np.arange(params[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
        ")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.xlabel(\"Boosting Iterations\")\n",
        "plt.ylabel(\"Deviance\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjlhIbZu8gEg"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5IbsX9i8gEh"
      },
      "outputs": [],
      "source": [
        "print(\"Linear Regression\")\n",
        "\n",
        "# Train the linear regression model on the training data\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using mean squared error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Obtain the feature importances\n",
        "importances = np.abs(regressor.coef_)\n",
        "\n",
        "# Create a list of feature names and their importances\n",
        "feature_importances = [(feature, importance) for feature, importance in zip(X_train.columns, importances)]\n",
        "\n",
        "# Sort the feature importances in descending order\n",
        "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Plot the feature importances\n",
        "features, importances = zip(*feature_importances)\n",
        "plt.bar(features, importances, align='center')\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKa9Bfx98gEh"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjWm6e4i8gEh"
      },
      "outputs": [],
      "source": [
        "print(\"Decision Tree Regression\")\n",
        "\n",
        "# Define the model\n",
        "dtr = DecisionTreeRegressor()\n",
        "\n",
        "# Define the hyperparameter grid to search\n",
        "param_grid = {'max_depth': [1, 2, 3, 4, 5],\n",
        "              'min_samples_split': [2, 4, 6, 8],\n",
        "              'min_samples_leaf': [1, 2, 3, 4]\n",
        "              }\n",
        "\n",
        "# Grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(dtr, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameter: \", grid_search.best_params_)\n",
        "\n",
        "# Use the best hyperparameters to train the final model\n",
        "dtr = grid_search.best_estimator_\n",
        "dtr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = dtr.predict(X_test)\n",
        "\n",
        "# Evaluate the model using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error: \", mse)\n",
        "\n",
        "# Evaluate the performance of the model using R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Obtain the feature importances\n",
        "importances = dtr.feature_importances_\n",
        "\n",
        "# Create a list of feature names and their importances\n",
        "feature_importances = [(feature, importance) for feature, importance in zip(X_train.columns, importances)]\n",
        "\n",
        "# Sort the feature importances in descending order\n",
        "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the feature importances\n",
        "'''for feature, importance in feature_importances:\n",
        "    print(feature, \":\", importance)\n",
        "'''\n",
        "\n",
        "# Plot the feature importances\n",
        "features, importances = zip(*feature_importances)\n",
        "plt.bar(features, importances, align='center')\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    \"\"\"Define the objective function\"\"\"\n",
        "    # train_x, valid_x, train_y, valid_y = train_test_split(X_train, y_train, test_size=0.15,random_state=42)\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 5),\n",
        "        'min_samples_split': trial.suggest_float(\"min_samples_split\", 0.01, 1),\n",
        "        'min_samples_leaf':  trial.suggest_float(\"min_samples_leaf\", 0.01, 0.5),\n",
        "        'random_state': 1\n",
        "    }\n",
        "\n",
        "    # Fit the model\n",
        "    model = DecisionTreeRegressor(**params)  \n",
        "    r2 = cross_val_score(model, X_train, y_train, cv=5, scoring = 'r2').mean()\n",
        "    return r2\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=280)\n",
        "trial = study.best_trial\n",
        "tuned_model = DecisionTreeRegressor(**trial.params) \n",
        "tuned_model.fit(X_train, y_train)\n",
        "y_preds = tuned_model.predict(X_test)\n",
        "r2_train = r2_score(y_train, tuned_model.predict(X_train))\n",
        "r2_test = r2_score(y_test, y_preds)\n",
        "print(\"R2 score for DecisionTreeRegressor model (test):\", r2_test)\n",
        "print(\"R2 score for DecisionTreeRegressor model (train):\", r2_train)"
      ],
      "metadata": {
        "id": "sKaiOEZFM-0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW3HqCzB8gEi"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C-DYz6l8gEi"
      },
      "outputs": [],
      "source": [
        "#Random Forest Regression\n",
        "print(\"Random Forest Regressor\")\n",
        "\n",
        "#Define the model\n",
        "regressor = RandomForestRegressor()\n",
        "\n",
        "#Define the hyperparameter grid to search\n",
        "param_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "                'max_depth': [5, 10, None],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4],\n",
        "                'max_leaf_nodes': [None, 10, 20],\n",
        "                }               \n",
        "\n",
        "#Grid search to find the best hyperparameter\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=regressor,\n",
        "    param_grid=param_grid,\n",
        "    scoring = 'r2',\n",
        "    n_jobs = -1,\n",
        "    cv = 5,\n",
        "    verbose=True\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameter: \", grid_search.best_params_)\n",
        "\n",
        "# Train the random forest regression model on the training data\n",
        "regressor = grid_search.best_estimator_\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using mean squared error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Evaluate the performance of the model using R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Obtain the feature importances\n",
        "importances = regressor.feature_importances_\n",
        "\n",
        "# Create a list of feature names and their importances\n",
        "feature_importances = [(feature, importance) for feature, importance in zip(X_train.columns, importances)]\n",
        "\n",
        "# Sort the feature importances in descending order\n",
        "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the feature importances\n",
        "'''for feature, importance in feature_importances:\n",
        "    print(feature, \":\", importance)\n",
        "'''\n",
        "\n",
        "# Plot the feature importances\n",
        "features, importances = zip(*feature_importances)\n",
        "plt.bar(features, importances, align='center')\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Optimization"
      ],
      "metadata": {
        "id": "yAcUPwD2N-ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    \"\"\"Define the objective function\"\"\"\n",
        "    # train_x, valid_x, train_y, valid_y = train_test_split(X_train, y_train, test_size=0.15,random_state=42)\n",
        "    params = {\n",
        "        # 'max_depth': trial.suggest_int('max_depth', 1, 31),\n",
        "        # 'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 20),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
        "        'min_samples_split': trial.suggest_loguniform('min_samples_split', 0.01, 1),\n",
        "        'min_samples_leaf': trial.suggest_loguniform('min_samples_split', 0.01, 1),\n",
        "        'random_state': 1\n",
        "    }\n",
        "\n",
        "    # Fit the model\n",
        "    model = RandomForestRegressor(**params)  \n",
        "    r2 = cross_val_score(model, X_train, y_train, cv=5, scoring = 'r2').mean()\n",
        "    return r2\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=280)\n",
        "\n",
        "trial = study.best_trial\n",
        "tuned_model = RandomForestRegressor(**trial.params) \n",
        "tuned_model.fit(X_train, y_train)\n",
        "y_preds = tuned_model.predict(X_test)\n",
        "r2_train = r2_score(y_train, tuned_model.predict(X_train))\n",
        "r2_test = r2_score(y_test, y_preds)\n",
        "print(\"R2 score for RandomForestRegressor model (test):\", r2_test)\n",
        "print(\"R2 score for RandomForestRegressor model (train):\", r2_train)"
      ],
      "metadata": {
        "id": "Qao3fStoGPcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "LxOhEcdXLW78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params = trial.best_params\n",
        "default_model = xgb.XGBRegressor()\n",
        "# model = xgb.XGBRegressor(**params)\n",
        "default_model.fit(X_train, y_train)\n",
        "y_preds = default_model.predict(X_test)\n",
        "r2_train = r2_score(y_train, default_model.predict(X_train))\n",
        "r2_test = r2_score(y_test, y_preds)\n",
        "print(\"R2 score for XGBoost model (test):\", r2_test)\n",
        "print(\"R2 score for XGBoost model (train):\", r2_train)\n",
        "\n",
        "params = {\n",
        "        'gamma': [0, 0.5, 1, 5],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 6, 10],\n",
        "        'n_estimators':[50,100,200],\n",
        "        }\n",
        "\n",
        "model = xgb.XGBRegressor() \n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=params,\n",
        "    scoring = 'r2',\n",
        "    n_jobs = -1,\n",
        "    cv = 5,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('Best Score: %s' % grid_search.best_score_)\n",
        "print('Best Hyperparameters: %s' % grid_search.best_params_)\n",
        "\n",
        "tuned_model = xgb.XGBRegressor(**grid_search.best_params_) \n",
        "tuned_model.fit(X_train, y_train)\n",
        "y_preds = tuned_model.predict(X_test)\n",
        "r2_train = r2_score(y_train, tuned_model.predict(X_train))\n",
        "r2_test = r2_score(y_test, y_preds)\n",
        "print(\"R2 score for XGBoost model (test):\", r2_test)\n",
        "print(\"R2 score for XGBoost model (train):\", r2_train)"
      ],
      "metadata": {
        "id": "4iDz-HWjLaxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    \"\"\"Define the objective function\"\"\"\n",
        "    # train_x, valid_x, train_y, valid_y = train_test_split(X_train, y_train, test_size=0.15,random_state=42)\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5, 6, 8, 11, 15, 18]),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.1, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.6, 0.7, 0.8, 0.9, 1.0]),\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
        "        'random_state': 1\n",
        "    }\n",
        "\n",
        "    # Fit the model\n",
        "    model = xgb.XGBRegressor(**params)  \n",
        "    r2 = cross_val_score(model, X_train, y_train, cv=5, scoring = 'r2').mean()\n",
        "    return r2\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=280)\n",
        "\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "trial = study.best_trial\n",
        "print('Best Value: {}'.format(trial.value))\n",
        "print('Best Params: ')\n",
        "\n",
        "for key, value in trial.params.items():\n",
        "    print('{}: {}'.format(key, value))\n",
        "\n",
        "tuned_model = xgb.XGBRegressor(**trial.params) \n",
        "tuned_model.fit(X_train, y_train)\n",
        "y_preds = tuned_model.predict(X_test)\n",
        "r2_train = r2_score(y_train, tuned_model.predict(X_train))\n",
        "r2_test = r2_score(y_test, y_preds)\n",
        "print(\"R2 score for XGBoost model (test):\", r2_test)\n",
        "print(\"R2 score for XGBoost model (train):\", r2_train)"
      ],
      "metadata": {
        "id": "lUYjZlOsLkBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFmlnH6y8gEi"
      },
      "source": [
        "## ANN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor"
      ],
      "metadata": {
        "id": "pzgTSRilAGDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(learning_rate = 1e-4, activation=\"relu\"):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(20,activation=activation))\n",
        "  model.add(Dense(20,activation=activation)) \n",
        "  model.add(Dense(20,activation=activation))\n",
        "  model.add(Dense(20,activation=activation))\n",
        "  model.add(Dense(20,activation=activation))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer=Adam(learning_rate),loss=\"mse\")\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "mQlEOxThNwJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search"
      ],
      "metadata": {
        "id": "cOoIc7F-Nwut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasRegressor(build_fn=create_model, verbose=1)\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "batches = [10, 100, 32, 64]\n",
        "activationFunction = ['relu','selu']\n",
        "epochs = [100, 1000, 2000]\n",
        "learning_rate = [1e-2, 1e-3, 1e-4]\n",
        "param_grid = dict(batch_size = batches,\n",
        "                  activation=activationFunction,\n",
        "                  epochs = epochs,\n",
        "                  learning_rate = learning_rate)\n",
        "search = GridSearchCV(model, param_grid=param_grid, return_train_score=True, cv=cv, n_jobs = -1)\n",
        "grid_result = search.fit(X_train.to_numpy(), y_train.to_numpy())\n",
        "# best result batch = 10, activation = relu, epoch = 1000, learning_rate = 1e-3"
      ],
      "metadata": {
        "id": "tr1eeFqMNdYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===========RESULTS============\")\n",
        "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean_accuracy, stdev, param in zip(means, stds, params):\n",
        "    print(f'mean={mean_accuracy:.4}, std={stdev:.4} using {param}')"
      ],
      "metadata": {
        "id": "aFhC_KdBNp-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Optimization"
      ],
      "metadata": {
        "id": "tlSL9OPXNz2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "trial = study.best_trial\n",
        "print('Best Value: {}'.format(trial.value))\n",
        "print('Best Params: ')\n",
        "\n",
        "for key, value in trial.params.items():\n",
        "    print('{}: {}'.format(key, value))\n",
        "\n",
        "tuned_model = KerasRegressor(**trial.params) \n",
        "hist = tuned_model.fit(X_train, y_train)\n",
        "y_preds = tuned_model.predict(X_test)\n",
        "r2_train = r2_score(y_train, tuned_model.predict(X_train))\n",
        "r2_test = r2_score(y_test, y_preds)\n",
        "print(\"R2 score for XGBoost model (test):\", r2_test)\n",
        "print(\"R2 score for XGBoost model (train):\", r2_train)"
      ],
      "metadata": {
        "id": "Iqcl3XHTaHsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)\n",
        "print(r2_score(pred, y_test.to_numpy().reshape(132, 1)))"
      ],
      "metadata": {
        "id": "at6Ta6vyNsrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fw29Y-1pNt4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NzrOvASaURz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dsproject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "c0452ec89d5da93c3200569f37c843a55610fea163ffd9caa1d4798a0a9f360b"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}